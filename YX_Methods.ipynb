{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#github 仓库名字：Autopilot_V2_Pytorch\n",
    "\n",
    "# 安装库文件\n",
    "import h5py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "\n",
    "# input mudule file\n",
    "import Py_autopilot2_module\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import imageio\n",
    "import scipy.io as sio \n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle   \n",
    "from sklearn.model_selection import train_test_split    #for split\n",
    "import math    #for pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#安装库文件\n",
    "pip install opencv_python -i https://pypi.mirrors.ustc.edu.cn/simple/       #中科大镜像源\n",
    "pip install -i https://pypi.tuna.tsinghua.edu.cn/simple opencv_python        #清华源\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#此部分为数据预处理部分\n",
    "\n",
    "##############################\n",
    "#数据类型转换\n",
    "##############################\n",
    "\n",
    "#数据标准化：\n",
    "(x-mean(x))/std(x)   ----Z-score\n",
    "\n",
    "#数据归一化：\n",
    "(x-min(x))/(max(x)-min(x))\n",
    "\n",
    "\n",
    "############################\n",
    "#如何查找本文件下有多少个jpg\n",
    "############################\n",
    "ls -lR | grep '.jpg' |wc -l\n",
    "\n",
    "################################################\n",
    "#transform 函数调用\n",
    "################################################\n",
    "transform_train = transforms.Compose([            #尽量输入PIL image\n",
    "    # transforms.Resize([h, w]),\n",
    "    # transforms.RandomCrop(32, padding=4),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),  #输入数据必须是unint8！可以是pil或者数组。将读取到的图片的维度进行转换（W,H,C转换为C,W,H）并将每个像素值除以255,转化成0-1之间。\n",
    "    # transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))   #x=(x-mean)/std， 转化成正态分布\n",
    "    transforms.Normalize((0.4343687,0.492617,0.51987326), (0.22204618,0.24065882,0.29102236))   #x=(x-mean)/std，把对应数据集算mean和std。转化成正态分布\n",
    "])\n",
    "\n",
    "# 举例\n",
    "features = np.array(features).astype(np.uint8)   #把features的数据类型转化成unit8，作为tranform.ToTensor的输入\n",
    "\n",
    "################################################\n",
    "#把数据从data.txt中读取出来，写入文件feature和labels.\n",
    "################################################\n",
    "def return_data():  \n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    features = []\n",
    "\n",
    "    with open(TRAIN_FILE) as fp:\n",
    "        for line in islice(fp, LIMIT):\n",
    "            # print(line)                           #0.jpg ~ 45405.jpg     data.txt Format: 45405.jpg 0.000000\n",
    "            path, angle = line.strip().split()\n",
    "            full_path = os.path.join(DATA_FOLDER, path)\n",
    "            X.append(full_path)\n",
    "            # using angles from -pi to pi to avoid rescaling the atan in the network\n",
    "            y.append(float(angle) * scipy.pi / 180)                        #得到pi值，而不是角度值\n",
    "\n",
    "    # print(\"lenth=\",len(X))  #data.txt lenth= 45406, but actually 45568 pics\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        img = plt.imread(X[i])              # X[i]= driving_dataset/0.jpg img shape= (256, 455, 3)\n",
    "        features.append(preprocess(img))    ## img shape= (100, 100, 3)\n",
    "\n",
    "    features = np.array(features).astype('float32')\n",
    "    labels = np.array(y).astype('float32')\n",
    "\n",
    "    print(features.shape)       #(45406, 100, 100, 3)\n",
    "    print(labels.shape)         #(45406,)\n",
    "    with open(\"features_HSV\", \"wb\") as f:                         #save data\n",
    "        pickle.dump(features, f, protocol=4)\n",
    "    with open(\"labels\", \"wb\") as f:\n",
    "        pickle.dump(labels, f, protocol=4)\n",
    "\n",
    "return_data()\n",
    "\n",
    "########################\n",
    "#找出label中steer的最大和最小值\n",
    "#########################\n",
    "\n",
    "LIMIT = None\n",
    "\n",
    "DATA_FOLDER = 'driving_dataset'\n",
    "TRAIN_FILE = os.path.join(DATA_FOLDER, 'data.txt')\n",
    "\n",
    "def preprocess(img):\n",
    "    # resized = cv2.resize((cv2.cvtColor(img, cv2.COLOR_RGB2HSV))[:, :, 1], (100, 100))  #取第二个通道\n",
    "    resized = cv2.resize(img, (100, 100))  #取RGB 3个通道 使用cv2.resize时，参数输入时宽×高×通道，需要注意\n",
    "    return resized\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "features = []\n",
    "\n",
    "with open(TRAIN_FILE) as fp:\n",
    "    for line in islice(fp, LIMIT):\n",
    "        path, angle = line.strip().split()\n",
    "        y.append(float(angle))\n",
    "\n",
    "labels = np.array(y).astype('float32')\n",
    "\n",
    "# print(features.shape)       #(45406, 100, 100, 3)\n",
    "print(np.max(labels))         #(45406,)\n",
    "print(np.min(labels))\n",
    "\n",
    "##############################################\n",
    "#计算训练集和测试集的 mean和std（每次新项目新数据集需要重新计算）\n",
    "##############################################\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch \n",
    " \n",
    "#load data shuffle and spilit\n",
    "features, labels = Py_autopilot2_module.loadFromPickle()   #shape:(45406, 100, 100) (45406,)\n",
    "\n",
    "#3/7分，并固定分配的随机数random_state=0,    train：31784 + test：13622\n",
    "train_features, test_features, train_label, test_label = train_test_split(features, labels, test_size=0.3,random_state=0)\n",
    "\n",
    "#train_features.shape = (31784, 100, 100, 3)\n",
    "temp_tr = train_features/255 #转化成0-1之间\n",
    "temp_te = test_features/255 #转化成0-1之间\n",
    "\n",
    "train_mean_0 = np.mean(temp_tr[:, :, :, 0])   #train dataset 0 channel的mean\n",
    "train_mean_1 = np.mean(temp_tr[:, :, :, 1])   #train dataset 1 channel的mean\n",
    "train_mean_2 = np.mean(temp_tr[:, :, :, 2])   #train dataset 2 channel的mean\n",
    "\n",
    "train_std_0 = np.std(temp_tr[:, :, :, 0])   #train dataset 0 channel的std\n",
    "train_std_1 = np.std(temp_tr[:, :, :, 1])   #train dataset 0 channel的std\n",
    "train_std_2 = np.std(temp_tr[:, :, :, 2])   #train dataset 0 channel的std\n",
    "\n",
    "test_mean_0 = np.mean(temp_te[:, :, :, 0])   #test dataset 0 channel的mean\n",
    "test_mean_1 = np.mean(temp_te[:, :, :, 1])   #test dataset 1 channel的mean\n",
    "test_mean_2 = np.mean(temp_te[:, :, :, 2])   #test dataset 2 channel的mean\n",
    "\n",
    "test_std_0 = np.std(temp_te[:, :, :, 0])   #test dataset 0 channel的std\n",
    "test_std_1 = np.std(temp_te[:, :, :, 1])   #test dataset 0 channel的std\n",
    "test_std_2 = np.std(temp_te[:, :, :, 2])   #test dataset 0 channel的std\n",
    "\n",
    "\n",
    "print(train_mean_0,train_mean_1,train_mean_2)     #0.4343687 0.492617 0.51987326\n",
    "print(train_std_0,train_std_1,train_std_2)        #0.22204618 0.24065882 0.29102236\n",
    "\n",
    "print(test_mean_0,test_mean_1,test_mean_2)     #0.43567735 0.49298695 0.5192303\n",
    "print(test_std_0,test_std_1,test_std_2)        #0.22272868 0.24110594 0.29045662\n",
    "\n",
    "###################################################################\n",
    "#存储的图片数量没有变，仅仅dataset和label进行水影评左右翻转，对应数组的长度增加一倍，\n",
    "###################################################################\n",
    "#训练数据集左右翻转增加一倍数量，label增加一倍并取相反数， 原shape:(31784, 100, 100, 3) \n",
    "train_features_lr = train_features[:,:,::-1,:] #所有照片水平左右翻转\n",
    "train_features = c = np.concatenate((train_features,train_features_lr),axis=0)    #针对0轴进行拼接 变成(63568, 100, 100, 3) \n",
    "train_label_lr = np.negative(train_label)\n",
    "train_label = np.concatenate((train_label,train_label_lr),axis=0)          #针对0轴进行拼接 变成(63568,) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#文件，图片的读写\n",
    "\n",
    "##################\n",
    "#读取二进制类型的文件\n",
    "##################\n",
    "def loadFromPickle():\n",
    "    with open(\"features_RGB\", \"rb\") as f:\n",
    "        features = np.array(pickle.load(f))\n",
    "    with open(\"labels\", \"rb\") as f:\n",
    "        labels = np.array(pickle.load(f))\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################\n",
    "#把数据从data.txt中读取出来，写入文件feature和labels.\n",
    "################################################\n",
    "def return_data():  \n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    features = []\n",
    "\n",
    "    with open(TRAIN_FILE) as fp:\n",
    "        for line in islice(fp, LIMIT):\n",
    "            # print(line)                           #0.jpg ~ 45405.jpg     data.txt Format: 45405.jpg 0.000000\n",
    "            path, angle = line.strip().split()\n",
    "            full_path = os.path.join(DATA_FOLDER, path)\n",
    "            X.append(full_path)\n",
    "            # using angles from -pi to pi to avoid rescaling the atan in the network\n",
    "            y.append(float(angle) * scipy.pi / 180)                        #得到pi值，而不是角度值\n",
    "\n",
    "    # print(\"lenth=\",len(X))  #data.txt lenth= 45406, but actually 45568 pics\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        img = plt.imread(X[i])              # X[i]= driving_dataset/0.jpg img shape= (256, 455, 3)\n",
    "        features.append(preprocess(img))    ## img shape= (100, 100, 3)\n",
    "\n",
    "    features = np.array(features).astype('float32')\n",
    "    labels = np.array(y).astype('float32')\n",
    "\n",
    "    print(features.shape)       #(45406, 100, 100, 3)\n",
    "    print(labels.shape)         #(45406,)\n",
    "    with open(\"features_HSV\", \"wb\") as f:                         #save data\n",
    "        pickle.dump(features, f, protocol=4)\n",
    "    with open(\"labels\", \"wb\") as f:\n",
    "        pickle.dump(labels, f, protocol=4)\n",
    "\n",
    "#######################\n",
    "#提取出单个图片进行保存\n",
    "#######################\n",
    "img_tmp = data_read['rgb']  #读取h5中保存的200张图片\n",
    "save_path = \"/home/yuxiao/projects/imitation-learning-master/train_data/SeqVal_dataset/\" + str(i + h5_cnt*200) + \".png\"\n",
    "imageio.imwrite(save_path,img_tmp[i]) #保存其中一张图片img_tmp[i]为特定名字.png\n",
    "\n",
    "#######################\n",
    "#保存.mat文件\n",
    "#######################\n",
    "#把字典保存为mat文件\n",
    "pic_name = str(i + h5_cnt*200) + \".png\" #record picture name\n",
    "label_steer = np.array(input_steer_tmp)\n",
    "label_steer_sub.update({pic_name: label_steer})\n",
    "sio.savemat(\"/home/yuxiao/projects/imitation-learning-master/train_data/SeqVal_mat/label_steer.mat\", label_steer_sub)\n",
    "\n",
    "#######################\n",
    "#读取.mat文件\n",
    "#######################\n",
    "label_dir='/home/yuxiao/projects/imitation-learning-master/train_data/'\n",
    "label_steer_file='label_steer.mat'\n",
    "label_steer = sio.loadmat(str(label_dir) + str(label_steer_file))   #dictionary: load all value from steer file\n",
    "print(label_steer)\n",
    "\n",
    "\n",
    "############################\n",
    "#Plt 读取图片并显示单张归一化图片\n",
    "############################\n",
    "#读出图片的格式为：\n",
    "img = plt.imread('driving_dataset/0.jpg')              # X[i]= driving_dataset/0.jpg\n",
    "img_resize = cv2.resize(img,(100,100))                  #取3个通道,  使用cv2.resize时，参数输入时宽×高×通道，需要注意\n",
    "\n",
    "\n",
    "img_tp=img   #采取数组操作\n",
    "pic = (img_tp - np.min(img_tp.flatten()))/(np.max(img_tp.flatten()) - np.min(img_tp.flatten()))#归一化操作图片数据\n",
    "\n",
    "# pic.swapaxes(0,2)    #交换通道对应轴\n",
    "plt.imshow(pic)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#图片，数组的相互转化\n",
    "\n",
    "##############################################\n",
    "######### for CV && PIL 相互之间的转化##########\n",
    "##############################################\n",
    "#PIL 的数据输入格式： N C W H\n",
    "#PLT 的数据输入格式： N W H C\n",
    "#CV2 的数据输入格式： N W H C\n",
    "\n",
    "# 通过cv2加载的图片，默认色道格式为BGR，可通过cv2.cvtColor函数进行转换；\n",
    "# 通过PIL加载的图片，默认色道格式为RGB，可通过图像的convert方法进行转换。\n",
    "def load_img_by_cv(file):\n",
    "    return cv2.imread(file)     #读出数组array？\n",
    "\n",
    "def load_img_by_PIL(file):\n",
    "    return Image.open(file)     #读出pil？\n",
    "\n",
    "def cv2PIL(img_cv):             #输入array\n",
    "    return Image.fromarray(cv2.cvtColor(img_cv,cv2.COLOR_BGR2RGB))\n",
    "\n",
    "def PIL2cv(img_pil):            #输入PIL\n",
    "    return cv2.cvtColor(np.asarray(img_pil),cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    \n",
    "#################################\n",
    "#array 转成PIL img\n",
    "#################################\n",
    "from PIL import Image\n",
    "img_array = np.array(train_features[0,:,:,:]).astype(np.uint8)\n",
    "img_temp = Image.fromarray(img_array)  #array 转成img\n",
    "# transform_train(img_temp)\n",
    "print(img_temp[0])\n",
    "\n",
    "#第二种方式\n",
    "img_arr = torch.from_numpy( np.array(train_features[0]) )\n",
    "answer = transforms.ToPILImage(mode='RGB')(img_arr)\n",
    "answer[:,:,0].show()\n",
    "\n",
    "#################################\n",
    "#PIL img 转成 array\n",
    "#################################\n",
    "X = []\n",
    "y = []\n",
    "features = []\n",
    "\n",
    "with open(TRAIN_FILE) as fp:\n",
    "    for line in islice(fp, LIMIT):\n",
    "        # print(line)                           #0.jpg ~ 45405.jpg     \"data.txt\" data Format: 45405.jpg 0.000000\n",
    "        path, angle = line.strip().split()\n",
    "        full_path = os.path.join(DATA_FOLDER, path)\n",
    "        X.append(full_path)\n",
    "\n",
    "\n",
    "for i in range(len(X)):\n",
    "    img = plt.imread(X[i])              # X[i]= driving_dataset/0.jpg; img shape= (256, 455, 3)\n",
    "    features.append(preprocess(img))    ## img shape= (100, 100, 3)\n",
    "\n",
    "features = np.array(features).astype('float32')   #使用cv2的时候要注意swap\n",
    "\n",
    "#################################\n",
    "#RGB 转成 HSV\n",
    "#################################\n",
    "\n",
    "# Opencv提供了cvtColor函数，调用该函数可以非常方便地实现不同颜色空间的转换。不过为了可视化，调用该函数得到的HSV图像，\n",
    "# 其H、S、V三通道的取值范围并不是0~360、0~1、0~1，而是经过转换的0~180、0~255、0~255。\n",
    "\n",
    "# https://www.cnblogs.com/weijiakai/p/15495607.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#显示照片\n",
    "\n",
    "########################\n",
    "#直接显示一张图片（输入为数组）\n",
    "########################\n",
    "plt.imshow(img_get[0].cpu().numpy().T)\n",
    "plt.show()\n",
    "\n",
    "#######################\n",
    "#显示归一化的多张图片（plt方式）\n",
    "#######################\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "print(features.shape)\n",
    "# print(features[0])\n",
    "\n",
    "# show iamge to see!\n",
    "# print first img in BATCH , check the input data should be   N x W x H x C\n",
    "\n",
    "img_tp = np.array(features[0,:,:,:])\n",
    "img_tp.swapaxes(0,2)\n",
    "temp = (img_tp - np.min(img_tp.flatten()))/(np.max(img_tp.flatten()) - np.min(img_tp.flatten()))\n",
    "plt.imshow(temp)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "###################\n",
    "#显示数组对应（PIL方式）\n",
    "###################\n",
    "fea_org = features[0:4]  #显示4张照片\n",
    "print(fea_org.shape)\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "# data is your array\n",
    "\n",
    "img = Image.fromarray(fea_org[0], 'RGB')\n",
    "img.show()\n",
    "img = Image.fromarray(fea_org[1], 'RGB')\n",
    "img = Image.fromarray(fea_org[2], 'RGB')\n",
    "img = Image.fromarray(fea_org[3], 'RGB')\n",
    "img.show()\n",
    "\n",
    "##########################\n",
    "#动态显示图片（运用流媒体的方式）\n",
    "##########################\n",
    "import os\n",
    "import cv2\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "imgbox = widgets.Image(format='jpg', height=300, width=400)\n",
    "display(imgbox)\n",
    "root = \"/media/yuxiao/C1/projects/Autopilot-master/Autopilot_V2/driving_dataset\"\n",
    "for file in os.listdir(root):\n",
    "    canvas = cv2.imread(os.path.join(root, file))\n",
    "    imgbox.value = cv2.imencode('.jpg', canvas)[1].tobytes()\n",
    "\n",
    "# 原文链接：https://blog.csdn.net/liuqixuan1994/article/details/88715454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数组&矩阵的常规操作\n",
    "\n",
    "##########\n",
    "#数组拼接\n",
    "##########\n",
    "a=np.array([[1,2,3],[4,5,6]])\n",
    "b=np.array([[21,22,23],[7,8,9]])\n",
    "c=np.concatenate((a,b),axis=0)\n",
    "print(a.shape,b.shape,c.shape)\n",
    "print(a)\n",
    "print(c)\n",
    "\n",
    "#########\n",
    "#\n",
    "\n",
    "\n",
    "##########################\n",
    "#把m x n整个矩阵展平\n",
    "##########################\n",
    "img_tp = img_get[0,:,:,:].numpy()\n",
    "img_tp.flatten()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#字典的处理\n",
    "\n",
    "##########################\n",
    "#显示字典的值 .keys  .values\n",
    "##########################\n",
    "#把字典的key和value的值取出来,按照顺序存入到list中 \n",
    "#创建字段\n",
    "d={'name':'cheng','age':20,'sex':'female'}\n",
    "#创建空列表\n",
    "a=[]\n",
    "#将字典中键和值循环取出添加到列表中\n",
    "for i in d.keys():\n",
    "a.append(i)\n",
    "a.append(d[i])\n",
    "print a\n",
    "\n",
    "##########################\n",
    "#求字典最大最小值\n",
    "##########################\n",
    "x=label_steer.values()  #取出所有values为字典\n",
    "y=list(x)               #字典转化为list\n",
    "y=np.array(y).squeeze() #list转化为np，（）增加维度才能变为数组\n",
    "z=np.empty(3200,float)\n",
    "for i in range(3200):\n",
    "    z[i]= y[i][0]\n",
    "print(min(z),max(z))\n",
    "或者\n",
    "min(zip(d.values(), d.keys()))\n",
    "或者\n",
    "x=label_steer.values()  #取出所有values为字典\n",
    "y=list(x)               #字典转化为list\n",
    "y=np.array(y).squeeze() #list转化为np，并减少维度\n",
    "y = x[:,0]              #取每一组的[0]\n",
    "\n",
    "##########################\n",
    "#计算字典alues的zscore值\n",
    "##########################\n",
    "import scipy.stats as stats\n",
    "keys, vals = zip(*d.items())\n",
    "z = stats.zscore(vals)\n",
    "\n",
    "##########################\n",
    "#合并两个list变成一个字典\n",
    "##########################\n",
    "newmap = dict(zip(keys,z))\n",
    "\n",
    "##########################\n",
    "#去掉字典里的值  （pop）\n",
    "##########################\n",
    "label_steer.pop('__header__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据类型转换\n",
    "\n",
    "##########################\n",
    "# CPU tensor和GPU tensor之间的转换\n",
    "##########################\n",
    "# （1）从CPU tensor到GPU tensor，使用\n",
    "data.cuda()\n",
    "\n",
    "# （2）从GPU tensor到CPU tensor，使用\n",
    "data.cpu()\n",
    "\n",
    "##########################\n",
    "# Tensor与Numpy array之间的转换\n",
    "##########################\n",
    "\n",
    "# （1）Tensor到Numpy array可以使用\n",
    "data.numpy()        #其中data的类型为torch.Tensor。\n",
    "\n",
    "# （2）Numpy array到Tensor可以使用\n",
    "torch.from_numpy(data)      #其中data的类型为numpy.ndarray。\n",
    "\n",
    "##########################\n",
    "# CPU tensor之间的转换或GPU tensor之间的转换\n",
    "##########################\n",
    "\n",
    "# （1）一般只要在tensor后加long()，int()，double()，float()，byte()等函数就能将tensor进行类型转换。\n",
    "\n",
    "# 例如：Torch.LongTensor转换为Torch.FloatTensor，直接使用data.float()即可。\n",
    "\n",
    "# （2）还可以使用type()函数。\n",
    "\n",
    "# 当data为tensor数据类型，如果使用data.type(torch.FloatTensor)则强制转换data为torch.FloatTensor类型张量。\n",
    "\n",
    "# （3）当不知道要转换为什么数据类型，但需要求a1，a2两个张量的乘积时，可以使用a1.type_as(a2)将a1转换为a2同类型。\n",
    "\n",
    "##########################\n",
    "# 数组astype的使用\n",
    "##########################\n",
    "features = np.array(features).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可视化参数\n",
    "\n",
    "#########################\n",
    "#visdom动态显示loss 和epoch\n",
    "#########################\n",
    "\n",
    "# pip install visdom\n",
    "# python -m visdom.server\n",
    "# visdom成功启动后，会返回一个网址，根据显示的网址然后在浏览器里输入：http://localhost:8097 进行登录\n",
    "\n",
    "from visdom import Visdom\n",
    "import time\n",
    "\n",
    "# 将窗口类实例化\n",
    "viz = Visdom() \n",
    "\n",
    "# 创建窗口并初始化\n",
    "viz.line([[0.,0.]], [0], win='train', opts=dict(title='loss&acc', legend=['loss', 'acc']))\n",
    "for global_steps in range(10):\n",
    "    # 随机获取loss和acc\n",
    "    loss = 0.1 * np.random.randn() + 1\n",
    "    acc = 0.1 * np.random.randn() + 0.5\n",
    "    # 更新窗口图像\n",
    "    viz.line([[loss, acc]], [global_steps], win='train', update='append')\n",
    "    # 延时0.5s\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存网络\n",
    "\n",
    "####################\n",
    "# 仅仅保存网络当前的参数\n",
    "####################\n",
    "model_par_name = 'results/model_img_par_{}.pkl'.format(epoch + 1)  #save each epoch\n",
    "torch.save(model.state_dict(), model_par_name)\n",
    "\n",
    "####################\n",
    "# 保存整个网络\n",
    "####################\n",
    "model_name = 'models/model_{}.pkl'.format(epoch + 1)  #save each epoch\n",
    "torch.save(model, model_name)  #保存网络和参数  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug\n",
    "\n",
    "#########################\n",
    "# 查网络输出问题：\n",
    "#########################\n",
    "# 先检查输入的数据\n",
    "# 然后逐步检查每一层网络的输入输出\n",
    "\n",
    "# 类中运用self.x  进行追踪每一层网络的输出\n",
    "# self.out = model.out来查看\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow 改写成pytorch\n",
    "\n",
    "#######################################################################\n",
    "#tensorflow转换pytorch问题padding='same' conversion to PyTorch padding=#\n",
    "#######################################################################\n",
    "###############################################\n",
    "# tensorflow转化成pytorch时候pads问题\n",
    "# padding='same' conversion to PyTorch padding=#\n",
    "###############################################\n",
    "\n",
    "# https://stackoverflow.com/questions/62166719/padding-same-conversion-to-pytorch-padding/62167204\n",
    "\n",
    "\n",
    "# In convolution padding = 1 for 3x3 kernel and stride=1 is ~ \"same\" in keras.\n",
    "\n",
    "# And In MaxPool you should set padding=0 (default), for 2x2 kernel, stride=2 is ~ \"same\" in keras.\n",
    "\n",
    "# You can use Formula:\n",
    "\n",
    "# Out = (W+2P-K)/S + 1\n",
    "\n",
    "# Let see some mathematical calculation:\n",
    "\n",
    "# For Convolution:\n",
    "\n",
    "# Case 1:\n",
    "\n",
    "# input is 30x30, kernel_size(K) is 3x3, stride=1, padding=1:\n",
    "\n",
    "# Out = (30+2*1-3)/1 + 1 = floor(29/1) + 1 = 30 i.e 30x30 (~ padding=\"same\")\n",
    "\n",
    "# Case 2:\n",
    "\n",
    "# input is 30x30, kernel_size(K) is 3x3, stride=1, padding=0:\n",
    "\n",
    "# Out = (30+2*0-3)/1 + 1 = floor(27/1) + 1 = 28 i.e 28x28 (~ padding=\"valid\")\n",
    "\n",
    "# For MaxPooling:\n",
    "\n",
    "# Case 1:\n",
    "\n",
    "# input is 30x30, kernel_size(K) is 2x2, stride=2, padding=0:\n",
    "\n",
    "# Out = (30+2*0-2)/2 + 1 = floor(28/2) + 1 = 15 i.e 15x15 (~ padding=\"same\")\n",
    "\n",
    "# Case 2:\n",
    "\n",
    "# input is 30x30, kernel_size(K) is 2x2, stride=2, padding=1:\n",
    "\n",
    "# Out = (30+2*1-2)/2 + 1 = floor(30/2) + 1 = 16 i.e 16x16 (~ padding=\"valid\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#安装carla遇到的问题总结\n",
    "###################################################################################\n",
    "# ubuntu20.04 系统因为做了系统升级，自动卸载了一些没用的包，到这原来可以运行的carla不能启动报错：\n",
    "# /opt/carla-simulator/CarlaUE4/Binaries/Linux/CarlaUE4-Linux-Shipping: error while loading shared libraries: \n",
    "# libomp.so.5: cannot open shared object file: No such file or directory\n",
    "\n",
    "# 解决方法：\n",
    "# 尝试重新安装 libosm5 包 \n",
    "# sudo apt-get install libomp5\n",
    "# 安装完成后再次启动carla成功。\n",
    "\n",
    "############################################\n",
    "# ERROR： GlobalShaderCache-GLSL_150_ES31.bin\n",
    "\n",
    "# 解决办法：\n",
    "# 安装游戏引擎vulkan\n",
    "# sudo apt install vulkan-utils"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
